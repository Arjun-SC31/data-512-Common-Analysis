{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65ecccdc",
   "metadata": {},
   "source": [
    "# Part 1 - Common Analysis - EPA AQI Data\n",
    "\n",
    "This notebook illustrates the steps taken towards laying the groundwork towards the project deliverables as part of the project component for DATA 512. This Notebook in particular deals with data procurement from the EPA [1]. This project focuses particularly on the city of Cheyenne, Wyoming."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8e79cb",
   "metadata": {},
   "source": [
    "# US EPA Air Quality System API Example *\n",
    "This illustrates how to request data from the US Environmental Protection Agency (EPA) Air Quality Service (AQS) API. This is a historical API and does not provide real-time air quality data. The [documentation](https://aqs.epa.gov/aqsweb/documents/data_api.html) for the API provides definitions of the different call parameter and examples of the various calls that can be made to the API.\n",
    "\n",
    "This notebook works systematically through example calls, requesting an API key, using 'list' to get various IDs and parameter values, and using 'daily summary' to get summary data that meets specific condistions. The notebook contains example function definitions that could be reused in other code. In general, the notebook explains each step along the way, referring back to possible output. Some of the explanations are tailored to the specific example requests of the API. Changing values to explore the results of the API is probably useful, but that will result in some explanations being out of sync with the outputs.\n",
    "\n",
    "The US EPA was created in the early 1970's. The EPA reports that they only started broad based monitoring with standardized quality assurance procedures in the 1980's. Many counties will have data starting somewhere between 1983 and 1988. However, some counties still do not have any air quality monitoring stations. The API helps resolve this by providing calls to search for monitoring stations and data using either station ids, or a county designation or a geographic bounding box. This example code provides examples of the county based and bounding box based API calls. Some [additional information on the Air Quality System can be found in the EPA FAQ](https://www.epa.gov/outdoor-air-quality-data/frequent-questions-about-airdata) on the system.\n",
    "\n",
    "The end goal is to get to some values that we might use for the Air Quality Index or AQI. You might see this reported on the news, most often around smog, but more frequently with regard to smoke. The AQI index is meant to tell us something about how healthy or clean the air is on any day. The AQI is actually a somewhat complext measure. When I started this example I looked up [how to calculate the AQI](https://www.airnow.gov/sites/default/files/2020-05/aqi-technical-assistance-document-sept2018.pdf) so that I would know roughly what goes into that value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a530c3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are standard python modules\n",
    "import json, time\n",
    "#\n",
    "#    The 'requests' module is a distribution module for making web requests.\n",
    "#\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81ff09d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "#\n",
    "#    CONSTANTS\n",
    "#\n",
    "\n",
    "#\n",
    "#    This is the root of all AQS API URLs\n",
    "#\n",
    "API_REQUEST_URL = 'https://aqs.epa.gov/data/api'\n",
    "\n",
    "#\n",
    "#    These are 'actions' we can ask the API to take or requests that we can make of the API\n",
    "#\n",
    "#    Sign-up request - generally only performed once - unless you lose your key\n",
    "API_ACTION_SIGNUP = '/signup?email={email}'\n",
    "#\n",
    "#    List actions provide information on API parameter values that are required by some other actions/requests\n",
    "API_ACTION_LIST_CLASSES = '/list/classes?email={email}&key={key}'\n",
    "API_ACTION_LIST_PARAMS = '/list/parametersByClass?email={email}&key={key}&pc={pclass}'\n",
    "API_ACTION_LIST_SITES = '/list/sitesByCounty?email={email}&key={key}&state={state}&county={county}'\n",
    "#\n",
    "#    Monitor actions are requests for monitoring stations that meet specific criteria\n",
    "API_ACTION_MONITORS_COUNTY = '/monitors/byCounty?email={email}&key={key}&param={param}&bdate={begin_date}&edate={end_date}&state={state}&county={county}'\n",
    "API_ACTION_MONITORS_BOX = '/monitors/byBox?email={email}&key={key}&param={param}&bdate={begin_date}&edate={end_date}&minlat={minlat}&maxlat={maxlat}&minlon={minlon}&maxlon={maxlon}'\n",
    "#\n",
    "#    Summary actions are requests for summary data. These are for daily summaries\n",
    "API_ACTION_DAILY_SUMMARY_COUNTY = '/dailyData/byCounty?email={email}&key={key}&param={param}&bdate={begin_date}&edate={end_date}&state={state}&county={county}'\n",
    "API_ACTION_DAILY_SUMMARY_BOX = '/dailyData/byBox?email={email}&key={key}&param={param}&bdate={begin_date}&edate={end_date}&minlat={minlat}&maxlat={maxlat}&minlon={minlon}&maxlon={maxlon}'\n",
    "#\n",
    "#    It is always nice to be respectful of a free data resource.\n",
    "#    We're going to observe a 100 requests per minute limit - which is fairly nice\n",
    "API_LATENCY_ASSUMED = 0.002       # Assuming roughly 2ms latency on the API and network\n",
    "API_THROTTLE_WAIT = (1.0/100.0)-API_LATENCY_ASSUMED\n",
    "#\n",
    "#\n",
    "#    This is a template that covers most of the parameters for the actions we might take, from the set of actions\n",
    "#    above. In the examples below, most of the time parameters can either be supplied as individual values to a\n",
    "#    function - or they can be set in a copy of the template and passed in with the template.\n",
    "# \n",
    "AQS_REQUEST_TEMPLATE = {\n",
    "    \"email\":      \"\",     \n",
    "    \"key\":        \"\",      \n",
    "    \"state\":      \"\",     # the two digit state FIPS # as a string\n",
    "    \"county\":     \"\",     # the three digit county FIPS # as a string\n",
    "    \"begin_date\": \"\",     # the start of a time window in YYYYMMDD format\n",
    "    \"end_date\":   \"\",     # the end of a time window in YYYYMMDD format, begin_date and end_date must be in the same year\n",
    "    \"minlat\":    0.0,\n",
    "    \"maxlat\":    0.0,\n",
    "    \"minlon\":    0.0,\n",
    "    \"maxlon\":    0.0,\n",
    "    \"param\":     \"\",     # a list of comma separated 5 digit codes, max 5 codes requested\n",
    "    \"pclass\":    \"\"      # parameter class is only used by the List calls\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4f8e58",
   "metadata": {},
   "source": [
    "I will need to request an API key to access the API. I should test access to the API to understand whether I can get data for my city based on the US County where my city is located, or whether I need to create a geodetic bounding box to access station data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46addfac",
   "metadata": {},
   "source": [
    "## Making a sign-up request *\n",
    "\n",
    "Before we can use the API, we need to request a key. We will use an email address to make the request. The EPA then sends a confirmation email link and a 'key' that we use for all other requests.\n",
    "\n",
    "We only need to sign-up once, unless we want to invalidate our current key (by getting a new key) or we lose our key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f0a61af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#    This implements the sign-up request. The parameters are standardized so that this function definition matches\n",
    "#    all of the others. However, the easiest way to call this is to simply call this function with your preferred\n",
    "#    email address.\n",
    "#\n",
    "def request_signup(email_address = None,\n",
    "                   endpoint_url = API_REQUEST_URL, \n",
    "                   endpoint_action = API_ACTION_SIGNUP, \n",
    "                   request_template = AQS_REQUEST_TEMPLATE,\n",
    "                   headers = None):\n",
    "    \n",
    "    # Make sure we have a string - if you don't have access to this email addres, things might go badly for you\n",
    "    if email_address:\n",
    "        request_template['email'] = email_address        \n",
    "    if not request_template['email']: \n",
    "        raise Exception(\"Must supply an email address to call 'request_signup()'\")\n",
    "    \n",
    "    # Compose the signup url - create a request URL by combining the endpoint_url with the parameters for the request\n",
    "    request_url = endpoint_url+endpoint_action.format(**request_template)\n",
    "        \n",
    "    # make the request\n",
    "    try:\n",
    "        # Wait first, to make sure we don't exceed a rate limit in the situation where an exception occurs\n",
    "        # during the request processing - throttling is always a good practice with a free data source\n",
    "        if API_THROTTLE_WAIT > 0.0:\n",
    "            time.sleep(API_THROTTLE_WAIT)\n",
    "        response = requests.get(request_url, headers=headers)\n",
    "        json_response = response.json()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        json_response = None\n",
    "    return json_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b992bee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#    A SIGNUP request is only to be done once, to request a key. A key is sent to that email address and needs to be confirmed with a click through\n",
    "#    This code should probably be commented out after you've made your key request to make sure you don't accidentally make a new sign-up request\n",
    "#\n",
    "#print(\"Requesting SIGNUP ...\")\n",
    "#response = request_signup(\"sagnik99@uw.edu\")\n",
    "#print(json.dumps(response,indent=4))\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d8594ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "USERNAME = \"arjuns31@uw.edu\"\n",
    "APIKEY= 'orangeheron29'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83225bdb",
   "metadata": {},
   "source": [
    "## Making a list request *\n",
    "Once you have a key, the next thing is to get information about the different types of air quality monitoring (sensors) and the different places where we might find air quality stations. The monitoring system is complex and changes all the time. The EPA implementation allows an API user to find changes to monitoring sites and sensors by making requests - maybe monthly, or daily. This API approach is probably better than having the EPA publish documentation that may be out of date as soon as it hits a web page. The one problem here is that some of the responses rely on jargon or terms-of-art. That is, one needs to know a bit about the way atmospheric sciece works to understand some of the terms. ... Good thing we can use the web to search for terms we don't know!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c2e85e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#    This implements the list request. There are several versions of the list request that only require email and key.\n",
    "#    This code sets the default action/requests to list the groups or parameter class descriptors. Having those descriptors \n",
    "#    allows one to request the individual (proprietary) 5 digit codes for individual air quality measures by using the\n",
    "#    param request. Some code in later cells will illustrate those requests.\n",
    "#\n",
    "def request_list_info(email_address = None, key = None,\n",
    "                      endpoint_url = API_REQUEST_URL, \n",
    "                      endpoint_action = API_ACTION_LIST_CLASSES, \n",
    "                      request_template = AQS_REQUEST_TEMPLATE,\n",
    "                      headers = None):\n",
    "    \n",
    "    #  Make sure we have email and key - at least\n",
    "    #  This prioritizes the info from the call parameters - not what's already in the template\n",
    "    if email_address:\n",
    "        request_template['email'] = email_address\n",
    "    if key:\n",
    "        request_template['key'] = key\n",
    "    \n",
    "    # For the basic request we need an email address and a key\n",
    "    if not request_template['email']:\n",
    "        raise Exception(\"Must supply an email address to call 'request_list_info()'\")\n",
    "    if not request_template['key']: \n",
    "        raise Exception(\"Must supply a key to call 'request_list_info()'\")\n",
    "\n",
    "    # compose the request\n",
    "    request_url = endpoint_url+endpoint_action.format(**request_template)\n",
    "        \n",
    "    # make the request\n",
    "    try:\n",
    "        # Wait first, to make sure we don't exceed a rate limit in the situation where an exception occurs\n",
    "        # during the request processing - throttling is always a good practice with a free data source\n",
    "        if API_THROTTLE_WAIT > 0.0:\n",
    "            time.sleep(API_THROTTLE_WAIT)\n",
    "        response = requests.get(request_url, headers=headers)\n",
    "        json_response = response.json()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        json_response = None\n",
    "    return json_response\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "883544b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"code\": \"AIRNOW MAPS\",\n",
      "        \"value_represented\": \"The parameters represented on AirNow maps (88101, 88502, and 44201)\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"ALL\",\n",
      "        \"value_represented\": \"Select all Parameters Available\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"AQI POLLUTANTS\",\n",
      "        \"value_represented\": \"Pollutants that have an AQI Defined\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"CORE_HAPS\",\n",
      "        \"value_represented\": \"Urban Air Toxic Pollutants\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"CRITERIA\",\n",
      "        \"value_represented\": \"Criteria Pollutants\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"CSN DART\",\n",
      "        \"value_represented\": \"List of CSN speciation parameters to populate the STI DART tool\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"FORECAST\",\n",
      "        \"value_represented\": \"Parameters routinely extracted by AirNow (STI)\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"HAPS\",\n",
      "        \"value_represented\": \"Hazardous Air Pollutants\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"IMPROVE CARBON\",\n",
      "        \"value_represented\": \"IMPROVE Carbon Parameters\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"IMPROVE_SPECIATION\",\n",
      "        \"value_represented\": \"PM2.5 Speciated Parameters Measured at IMPROVE sites\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"MET\",\n",
      "        \"value_represented\": \"Meteorological Parameters\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"NATTS CORE HAPS\",\n",
      "        \"value_represented\": \"The core list of toxics of interest to the NATTS program.\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"NATTS REQUIRED\",\n",
      "        \"value_represented\": \"Required compounds to be collected in the National Air Toxics Network\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"PAMS\",\n",
      "        \"value_represented\": \"Photochemical Assessment Monitoring System\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"PAMS_VOC\",\n",
      "        \"value_represented\": \"Volatile Organic Compound subset of the PAMS Parameters\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"PM COARSE\",\n",
      "        \"value_represented\": \"PM between 2.5 and 10 micrometers\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"PM10 SPECIATION\",\n",
      "        \"value_represented\": \"PM10 Speciated Parameters\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"PM2.5 CONT NONREF\",\n",
      "        \"value_represented\": \"PM2.5 Continuous, Nonreference Methods\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"PM2.5 MASS/QA\",\n",
      "        \"value_represented\": \"PM2.5 Mass and QA Parameters\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"SCHOOL AIR TOXICS\",\n",
      "        \"value_represented\": \"School Air Toxics Program Parameters\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"SPECIATION\",\n",
      "        \"value_represented\": \"PM2.5 Speciated Parameters\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"SPECIATION CARBON\",\n",
      "        \"value_represented\": \"PM2.5 Speciation Carbon Parameters\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"SPECIATION CATION/ANION\",\n",
      "        \"value_represented\": \"PM2.5 Speciation Cation/Anion Parameters\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"SPECIATION METALS\",\n",
      "        \"value_represented\": \"PM2.5 Speciation Metal Parameters\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"UATMP CARBONYL\",\n",
      "        \"value_represented\": \"Urban Air Toxics Monitoring Program Carbonyls\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"UATMP VOC\",\n",
      "        \"value_represented\": \"Urban Air Toxics Monitoring Program VOCs\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"VOC\",\n",
      "        \"value_represented\": \"Volatile organic compounds\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#   The default should get us a list of the various groups or classes of sensors. These classes are user defined names for clustors of\n",
    "#   sensors that might be part of a package or default air quality sensing station. We need a class name to start getting down to the\n",
    "#   a sensor ID. Each sensor type has an ID number. We'll eventually need those ID numbers to be able to request values that come from\n",
    "#   that specific sensor.\n",
    "#\n",
    "request_data = AQS_REQUEST_TEMPLATE.copy()\n",
    "request_data['email'] = USERNAME\n",
    "request_data['key'] = APIKEY\n",
    "\n",
    "response = request_list_info(request_template=request_data)\n",
    "\n",
    "if response[\"Header\"][0]['status'] == \"Success\":\n",
    "    print(json.dumps(response['Data'],indent=4))\n",
    "else:\n",
    "    print(json.dumps(response,indent=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414b24be",
   "metadata": {},
   "source": [
    "We're interested in getting to something that might be the Air Quality Index (AQI). You see this reported on the news - often around smog values, but also when there is smoke in the sky. The AQI is a complex measure of different gasses and of the particles in the air (dust, dirt, ash ...).\n",
    "\n",
    "From the list produced by our 'list/Classes' request above, it looks like there is a class of sensors called \"AQI POLLUTANTS\". Let's try to get a list of those specific sensors and see what we can get from those.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c80631f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#   Once we have a list of the classes or groups of possible sensors, we can find the sensor IDs that make up that class (group)\n",
    "#   The one that looks to be associated with the Air Quality Index is \"AQI POLLUTANTS\"\n",
    "#   We'll use that to make another list request.\n",
    "#\n",
    "AQI_PARAM_CLASS = \"AQI POLLUTANTS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf96dbab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"code\": \"42101\",\n",
      "        \"value_represented\": \"Carbon monoxide\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"42401\",\n",
      "        \"value_represented\": \"Sulfur dioxide\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"42602\",\n",
      "        \"value_represented\": \"Nitrogen dioxide (NO2)\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"44201\",\n",
      "        \"value_represented\": \"Ozone\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"81102\",\n",
      "        \"value_represented\": \"PM10 Total 0-10um STP\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"88101\",\n",
      "        \"value_represented\": \"PM2.5 - Local Conditions\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"88502\",\n",
      "        \"value_represented\": \"Acceptable PM2.5 AQI & Speciation Mass\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#   Structure a request to get the sensor IDs associated with the AQI\n",
    "#\n",
    "request_data = AQS_REQUEST_TEMPLATE.copy()\n",
    "request_data['email'] = USERNAME\n",
    "request_data['key'] = APIKEY\n",
    "request_data['pclass'] = AQI_PARAM_CLASS  # here we specify that we want this 'pclass' or parameter classs\n",
    "\n",
    "response = request_list_info(request_template=request_data, endpoint_action=API_ACTION_LIST_PARAMS)\n",
    "\n",
    "if response[\"Header\"][0]['status'] == \"Success\":\n",
    "    print(json.dumps(response['Data'],indent=4))\n",
    "else:\n",
    "    print(json.dumps(response,indent=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629ec058",
   "metadata": {},
   "source": [
    "### Handling API Intricacies\n",
    "\n",
    "The above procedure has provided us with a response that contains sensor IDs. The description and the name for every sensor is also included. The API has placed some limits on call parameters, it is not possible to request all the AQI parameters in a single request. The user can only request 5 different sensor values at a time. Hence, the process for acquiring all the parameters will have to be split up.\n",
    "\n",
    "We would essentially be repeating the process, except that with each repetition we would acquire data for different groups of parameters. The data is acquired by splitting the requests by the kind of data collected by the sensors, as mentioned below:\n",
    "\n",
    "Data collected by different requests:\n",
    "1. Sensors collecting gas data\n",
    "2. Sensors collecting particulate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b3bfd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given the set of sensor codes, now we can create a parameter list or 'param' value as defined by the AQS API spec.\n",
    "# It turns out that we want all of these measures for AQI, but we need to have two different param constants to get\n",
    "# all seven of the code types. We can only have a max of 5 sensors/values request per param.\n",
    "\n",
    "#   Gaseous AQI pollutants CO, SO2, NO2, and O2\n",
    "AQI_PARAMS_GASEOUS = \"42101,42401,42602,44201\"\n",
    "#   Particulate AQI pollutants PM10, PM2.5, and Acceptable PM2.5\n",
    "AQI_PARAMS_PARTICULATES = \"81102,88101,88502\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a0b4e8",
   "metadata": {},
   "source": [
    "Air quality monitoring stations are located all over the US at different locations. We will need some sample locations to experiment with different locations to see what kinds of values come back from different sensor requests.\n",
    "\n",
    "This list includes the [FIPS](https://www.census.gov/library/reference/code-lists/ansi.html) number for the state and county as a 5 digit string. This format, the 5 digit string, is a 'old' format that is still widely used. There are new codes that may eventually be adopted for the US government information systems. But FIPS is currently what the AQS uses, so that's what is in the list as the constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e36c8067",
   "metadata": {},
   "outputs": [],
   "source": [
    "CITY_LOCATIONS = {\n",
    "    'cheyenne' :       {'city'   : 'Cheyenne',\n",
    "                       'county' : 'Laramie',\n",
    "                       'state'  : 'Wyoming',\n",
    "                       'fips'   : '56021',\n",
    "                       'latlon' : [41.1400, -104.8202] }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c68861cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"code\": \"0001\",\n",
      "        \"value_represented\": \"Cheyenne SLAMS site\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"0002\",\n",
      "        \"value_represented\": \"Cheyenne Mobile\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"0003\",\n",
      "        \"value_represented\": \"Laramie County Mobile\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"0004\",\n",
      "        \"value_represented\": \"Laramie County Mobile\"\n",
      "    },\n",
      "    {\n",
      "        \"code\": \"0100\",\n",
      "        \"value_represented\": \"Cheyenne NCore\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#  This list request should give us a list of all the monitoring stations in the county specified by the\n",
    "#  given city selected from the CITY_LOCATIONS dictionary\n",
    "#\n",
    "request_data = AQS_REQUEST_TEMPLATE.copy()\n",
    "request_data['email'] = USERNAME\n",
    "request_data['key'] = APIKEY\n",
    "request_data['state'] = CITY_LOCATIONS['cheyenne']['fips'][:2]   # the first two digits (characters) of FIPS is the state code\n",
    "request_data['county'] = CITY_LOCATIONS['cheyenne']['fips'][2:]  # the last three digits (characters) of FIPS is the county code\n",
    "\n",
    "response = request_list_info(request_template=request_data, endpoint_action=API_ACTION_LIST_SITES)\n",
    "\n",
    "if response[\"Header\"][0]['status'] == \"Success\":\n",
    "    print(json.dumps(response['Data'],indent=4))\n",
    "else:\n",
    "    print(json.dumps(response,indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89de700b",
   "metadata": {},
   "source": [
    "The above response gives us a list of monitoring stations. Each monitoring station has a unique \"code\" which is a string number, and, sometimes, a description. The description seems to be something about where the monitoring station is located."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906f3875",
   "metadata": {},
   "source": [
    "## Making a daily summary request *\n",
    "\n",
    "The function below is designed to encapsulate requests to the EPA AQS API. When calling the function one should create/copy a parameter template, then initialize that template with values that won't change with each call. Then on each call simply pass in the parameters that need to change, like date ranges.\n",
    "\n",
    "Another function below provides an example of extracting values and restructuring the response to make it a little more usable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0a621c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#    This implements the daily summary request. Daily summary provides a daily summary value for each sensor being requested\n",
    "#    from the start date to the end date. \n",
    "#\n",
    "#    Like the two other functions, this can be called with a mixture of a defined parameter dictionary, or with function\n",
    "#    parameters. If function parameters are provided, those take precedence over any parameters from the request template.\n",
    "#\n",
    "def request_daily_summary(email_address = None, key = None, param=None,\n",
    "                          begin_date = None, end_date = None, fips = None,\n",
    "                          endpoint_url = API_REQUEST_URL, \n",
    "                          endpoint_action = API_ACTION_DAILY_SUMMARY_COUNTY, \n",
    "                          request_template = AQS_REQUEST_TEMPLATE,\n",
    "                          headers = None):\n",
    "    \n",
    "    #  This prioritizes the info from the call parameters - not what's already in the template\n",
    "    if email_address:\n",
    "        request_template['email'] = email_address\n",
    "    if key:\n",
    "        request_template['key'] = key\n",
    "    if param:\n",
    "        request_template['param'] = param\n",
    "    if begin_date:\n",
    "        request_template['begin_date'] = begin_date\n",
    "    if end_date:\n",
    "        request_template['end_date'] = end_date\n",
    "    if fips and len(fips)==5:\n",
    "        request_template['state'] = fips[:2]\n",
    "        request_template['county'] = fips[2:]            \n",
    "\n",
    "    # Make sure there are values that allow us to make a call - these are always required\n",
    "    if not request_template['email']:\n",
    "        raise Exception(\"Must supply an email address to call 'request_daily_summary()'\")\n",
    "    if not request_template['key']: \n",
    "        raise Exception(\"Must supply a key to call 'request_daily_summary()'\")\n",
    "    if not request_template['param']: \n",
    "        raise Exception(\"Must supply param values to call 'request_daily_summary()'\")\n",
    "    if not request_template['begin_date']: \n",
    "        raise Exception(\"Must supply a begin_date to call 'request_daily_summary()'\")\n",
    "    if not request_template['end_date']: \n",
    "        raise Exception(\"Must supply an end_date to call 'request_daily_summary()'\")\n",
    "    # Note we're not validating FIPS fields because not all of the daily summary actions require the FIPS numbers\n",
    "        \n",
    "    # compose the request\n",
    "    request_url = endpoint_url+endpoint_action.format(**request_template)\n",
    "        \n",
    "    # make the request\n",
    "    try:\n",
    "        # Wait first, to make sure we don't exceed a rate limit in the situation where an exception occurs\n",
    "        # during the request processing - throttling is always a good practice with a free data source\n",
    "        if API_THROTTLE_WAIT > 0.0:\n",
    "            time.sleep(API_THROTTLE_WAIT)\n",
    "        response = requests.get(request_url, headers=headers)\n",
    "        json_response = response.json()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        json_response = None\n",
    "    return json_response\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20b3527",
   "metadata": {},
   "source": [
    "### Extracting Particulate Data\n",
    "\n",
    "There is substantial repetition in the daily summary response. Also, one can only request data from a single year at a time. The process is thus iterated through from 1973 (EPA's establishement) to present day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "988c3452",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#    This is a list of field names - data - that will be extracted from each record\n",
    "#\n",
    "EXTRACTION_FIELDS = ['sample_duration','observation_count','arithmetic_mean','aqi']\n",
    "\n",
    "#\n",
    "#    The function creates a summary record\n",
    "def summary_extraction(r=None, fields=EXTRACTION_FIELDS):\n",
    "    \n",
    "    '''\n",
    "    This function extracts the relevant data from the API response. We extract the fields which are required.\n",
    "    The function also creates a summary for each monitoring site.\n",
    "\n",
    "    '''\n",
    "    ## the result will be structured around monitoring site, parameter, and then date\n",
    "    result = dict()\n",
    "    data = r[\"Data\"]\n",
    "    for record in data:\n",
    "        # make sure the record is set up\n",
    "        site = record['site_number']\n",
    "        param = record['parameter_code']\n",
    "        #date = record['date_local']    # this version keeps the respnse value YYYY-\n",
    "        date = record['date_local'].replace('-','') # this puts it in YYYYMMDD format\n",
    "        if site not in result:\n",
    "            result[site] = dict()\n",
    "            result[site]['local_site_name'] = record['local_site_name']\n",
    "            result[site]['site_address'] = record['site_address']\n",
    "            result[site]['state'] = record['state']\n",
    "            result[site]['county'] = record['county']\n",
    "            result[site]['city'] = record['city']\n",
    "            result[site]['pollutant_type'] = dict()\n",
    "        if param not in result[site]['pollutant_type']:\n",
    "            result[site]['pollutant_type'][param] = dict()\n",
    "            result[site]['pollutant_type'][param]['parameter_name'] = record['parameter']\n",
    "            result[site]['pollutant_type'][param]['units_of_measure'] = record['units_of_measure']\n",
    "            result[site]['pollutant_type'][param]['method'] = record['method']\n",
    "            result[site]['pollutant_type'][param]['data'] = dict()\n",
    "        if date not in result[site]['pollutant_type'][param]['data']:\n",
    "            result[site]['pollutant_type'][param]['data'][date] = list()\n",
    "        \n",
    "        # now extract the specified fields\n",
    "        extract = dict()\n",
    "        for k in fields:\n",
    "            if str(k) in record:\n",
    "                extract[str(k)] = record[k]\n",
    "            else:\n",
    "                # this makes sure we always have the requested fields, even if\n",
    "                # we have a missing value for a given day/month\n",
    "                extract[str(k)] = None\n",
    "        \n",
    "        # add this extraction to the list for the day\n",
    "        result[site]['pollutant_type'][param]['data'][date].append(extract)\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28d77576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for 1973 not available.\n",
      "Data for 1974 not available.\n",
      "Data for 1975 not available.\n",
      "Data for 1976 not available.\n",
      "Data for 1977 not available.\n",
      "Data for 1978 not available.\n",
      "Data for 1979 not available.\n",
      "Data for 1980 not available.\n",
      "Data for 1981 not available.\n",
      "Data for 1982 not available.\n",
      "Data for 1983 not available.\n",
      "Data for 1989 not available.\n",
      "Data for 1990 not available.\n",
      "Particulate data response:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "request_data = AQS_REQUEST_TEMPLATE.copy()\n",
    "request_data['email'] = USERNAME\n",
    "request_data['key'] = APIKEY\n",
    "request_data['param'] = AQI_PARAMS_PARTICULATES\n",
    "request_data['state'] = CITY_LOCATIONS['cheyenne']['fips'][:2]\n",
    "request_data['county'] = CITY_LOCATIONS['cheyenne']['fips'][2:]\n",
    "\n",
    "particulates = []\n",
    "\n",
    "# Define the request template and base URL\n",
    "request_template = \"YOUR_REQUEST_TEMPLATE_HERE\"\n",
    "base_url = \"YOUR_BASE_URL_HERE\"\n",
    "\n",
    "\n",
    "# Loop through the years and request daily summary data\n",
    "for year in range(1973, 2024):\n",
    "    begin_date = f\"{year}0101\"\n",
    "    end_date = f\"{year}1231\"\n",
    "\n",
    "    # Make the request for the current year\n",
    "    particulate_aqi = request_daily_summary(request_template=request_data, begin_date=begin_date, end_date=end_date)\n",
    "    \n",
    "    # Check the response and append data to the list\n",
    "    if particulate_aqi[\"Header\"][0]['status'] == \"Success\":\n",
    "        #all_gaseous_data.extend(gaseous_aqi['Data'])\n",
    "        extract_particulate = summary_extraction(particulate_aqi)\n",
    "        #print(\"Summary of particulate extraction ...\")\n",
    "        #print(json.dumps(extract_gaseous,indent=4))\n",
    "        particulates.append(extract_particulate)\n",
    "        \n",
    "    elif particulate_aqi[\"Header\"][0]['status'].startswith(\"No data \"):\n",
    "        print(f\"Data for {year} not available.\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"Error acquiring {year} data.\")\n",
    "\n",
    "# Print or process the collected data\n",
    "print(\"Particulate data response:\")\n",
    "print(json.dumps(particulates, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81f00681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Successfully written.\n"
     ]
    }
   ],
   "source": [
    "particulate_file = \"particulate_pollutant_data.json\"\n",
    "\n",
    "with open(particulate_file, 'w') as file:\n",
    "    json.dump(particulates, file, indent=4)\n",
    "\n",
    "print(f\"Data Successfully written.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788e26f0",
   "metadata": {},
   "source": [
    "### Extracting Gaseous Data\n",
    "\n",
    "There is substantial repetition in the daily summary response. Also, one can only request data from a single year at a time. The process is thus iterated through from 1973 (EPA's establishement) to present day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e17dc8a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data not available for 1986.\n",
      "Data not available for 1987.\n",
      "Data not available for 1988.\n",
      "Data not available for 1989.\n",
      "Data not available for 1990.\n",
      "Data not available for 1991.\n",
      "Data not available for 1992.\n",
      "Data not available for 1993.\n",
      "Data not available for 1994.\n",
      "Data not available for 1995.\n",
      "Data not available for 1996.\n",
      "Data not available for 1997.\n",
      "Data not available for 1998.\n",
      "Data not available for 1999.\n",
      "Data not available for 2000.\n",
      "Data not available for 2001.\n",
      "Data not available for 2002.\n",
      "Data not available for 2003.\n",
      "Data not available for 2004.\n",
      "Data not available for 2005.\n",
      "Data not available for 2006.\n",
      "Data not available for 2007.\n",
      "Data not available for 2008.\n",
      "Data not available for 2009.\n",
      "Data not available for 2010.\n",
      "Gaseous Data Response: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "request_data = AQS_REQUEST_TEMPLATE.copy()\n",
    "request_data['email'] = USERNAME\n",
    "request_data['key'] = APIKEY\n",
    "request_data['param'] = AQI_PARAMS_GASEOUS\n",
    "request_data['state'] = CITY_LOCATIONS['cheyenne']['fips'][:2]\n",
    "request_data['county'] = CITY_LOCATIONS['cheyenne']['fips'][2:]\n",
    "\n",
    "gaseous = []\n",
    "request_template = \"YOUR_REQUEST_TEMPLATE_HERE\"\n",
    "base_url = \"YOUR_BASE_URL_HERE\"\n",
    "\n",
    "for year in range(1973, 2024):\n",
    "    begin_date = f\"{year}0101\"\n",
    "    end_date = f\"{year}1231\"\n",
    "\n",
    "    gaseous_aqi = request_daily_summary(request_template=request_data, begin_date=begin_date, end_date=end_date)\n",
    "    \n",
    "    if gaseous_aqi[\"Header\"][0]['status'] == \"Success\":\n",
    "        gaseous_data = summary_extraction(gaseous_aqi)\n",
    "        gaseous.append(gaseous_data)\n",
    "        \n",
    "    elif gaseous_aqi[\"Header\"][0]['status'].startswith(\"No data \"):\n",
    "        print(f\"Data not available for {year}.\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"Error acquiring {year} data.\")\n",
    "\n",
    "print(\"Gaseous Data Response: \")\n",
    "print(json.dumps(gaseous, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3d5a155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Successfully written.\n"
     ]
    }
   ],
   "source": [
    "gaseous_file = \"gaseous_pollutant_data.json\"\n",
    "\n",
    "with open(gaseous_file, 'w') as file:\n",
    "    json.dump(gaseous, file, indent=4)\n",
    "\n",
    "print(f\"Data Successfully written.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b1a014b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aqi_access(data, dynamic_keys=None):\n",
    "    '''\n",
    "    The raw AQI list of dictionaries is taken as input. From this, the AQI, the sample duration, and the date of record are extracted.\n",
    "    '''\n",
    "    if dynamic_keys is None:\n",
    "        dynamic_keys = []\n",
    "\n",
    "    extracted = []\n",
    "\n",
    "    for key, value in data.items():\n",
    "        current_keys = dynamic_keys + [key]\n",
    "\n",
    "        if isinstance(value, dict):\n",
    "            extracted.extend(aqi_access(value, current_keys))\n",
    "        elif isinstance(value, list):\n",
    "            for item in value:\n",
    "                if isinstance(item, dict):\n",
    "                    aqi = item.get(\"aqi\")\n",
    "                    sample_duration = item.get(\"sample_duration\")\n",
    "                    if aqi is not None:\n",
    "                        extracted.append({\"keys\": current_keys,\"sample_duration\": sample_duration, \"aqi\": aqi})\n",
    "\n",
    "    return extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cef6c13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "particulate_extracted = []\n",
    "\n",
    "for data in particulates:\n",
    "    particulate_extracted.extend(aqi_access(data))\n",
    "\n",
    "# Print or further process the extracted data\n",
    "for entry in particulate_extracted:\n",
    "    keys = \" > \".join(entry[\"keys\"])\n",
    "    aqi = entry[\"aqi\"]\n",
    "    sample = entry['sample_duration']\n",
    "    print(f\"Keys: {keys}, AQI: {aqi} , SAMPLE: {sample}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d59b1ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gaseous_extracted = []\n",
    "\n",
    "# Iterate through the list of datasets\n",
    "for data in gaseous:\n",
    "    gaseous_extracted.extend(aqi_access(data))\n",
    "\n",
    "# Print or further process the extracted data\n",
    "for entry in gaseous_extracted:\n",
    "    keys = \" > \".join(entry[\"keys\"])\n",
    "    aqi = entry[\"aqi\"]\n",
    "    sample = entry['sample_duration']\n",
    "    print(f\"Keys: {keys}, AQI: {aqi} , SAMPLE: {sample}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f9af869d",
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_particulate_data = []\n",
    "\n",
    "for entry in particulate_extracted:\n",
    "    keys = entry['keys']\n",
    "    date = keys[-1]\n",
    "    aqi = entry['aqi']\n",
    "    sample_duration = entry['sample_duration']\n",
    "    pollutant_type = keys[-3]\n",
    "\n",
    "    formatted_particulate_data.append({'Date': date, 'AQI': aqi, 'Sample_Duration': sample_duration, 'Pollutant_Type': pollutant_type})\n",
    "\n",
    "particulate_df = pd.DataFrame(formatted_particulate_data)\n",
    "\n",
    "particulate_df['Date'] = pd.to_datetime(particulate_df['Date'], format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d71f4fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_gaseous_data = []\n",
    "\n",
    "for entry in gaseous_extracted:\n",
    "    keys = entry['keys']\n",
    "    date = keys[-1]\n",
    "    aqi = entry['aqi']\n",
    "    sample_duration = entry['sample_duration']\n",
    "    pollutant_type = keys[-3]\n",
    "\n",
    "    formatted_gaseous_data.append({'Date': date, 'AQI': aqi, 'Sample_Duration': sample_duration, 'Pollutant_Type': pollutant_type})\n",
    "\n",
    "gaseous_df = pd.DataFrame(formatted_gaseous_data)\n",
    "\n",
    "gaseous_df['Date'] = pd.to_datetime(gaseous_df['Date'], format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7db89eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "gaseous_df.to_csv(\"gaseous_aqi.csv\")\n",
    "particulate_df.to_csv(\"particulate_aqi.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34615b5",
   "metadata": {},
   "source": [
    "### Final Data Operations\n",
    "\n",
    "The final stages of data preparation of the data obtained from the EPA AQI API are performed as follows.\n",
    "\n",
    "1. Columns deemed unnecessary for analysis are removed.\n",
    "\n",
    "2. Following this, the data is grouped by date, and the average air quality measurements for each date are computed, consolidating the results into a single DataFrame.\n",
    "\n",
    "3. Next, a unified Air Quality Index (AQI) is calculated from individual gaseous and particulate AQI values, with missing values filled in as necessary.\n",
    "\n",
    "4. Subsequently, the code extracts the year information from the 'Date' column, groups the data by year, and calculates the mean AQI for each year.\n",
    "\n",
    "The 'aqi_yearly_data' stores the yearly AQI data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c83b9b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "particulate_df = particulate_df.drop(['Sample_Duration', 'Pollutant_Type'], axis=1)\n",
    "gaseous_df = gaseous_df.drop(['Sample_Duration', 'Pollutant_Type'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c042bd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'Date' and calculate the mean for each group\n",
    "particulate_mean = particulate_df.groupby('Date', as_index=False).mean()\n",
    "gaseous_mean = gaseous_df.groupby('Date', as_index=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0f744b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the DataFrames on 'Date' and take the maximum AQI or fill with values from either DataFrame\n",
    "merged_df = gaseous_mean.merge(particulate_mean, on='Date', how='outer', suffixes=('_gaseous', '_particulate'))\n",
    "merged_df['AQI'] = merged_df[['AQI_gaseous', 'AQI_particulate']].max(axis=1)\n",
    "merged_df['AQI'].fillna(merged_df['AQI_gaseous'].combine_first(merged_df['AQI_particulate']), inplace=True)\n",
    "merged_df.drop(columns=['AQI_gaseous', 'AQI_particulate'], inplace=True)\n",
    "\n",
    "merged_df['Year'] = merged_df['Date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "196c1c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'Year' and calculate the mean AQI for each year\n",
    "aqi_yearly_data = merged_df.groupby('Year')['AQI'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "920de5ea",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>AQI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1984</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1985</td>\n",
       "      <td>21.385965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1986</td>\n",
       "      <td>15.786885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1987</td>\n",
       "      <td>26.490000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1988</td>\n",
       "      <td>16.546296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1991</td>\n",
       "      <td>18.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1992</td>\n",
       "      <td>15.396552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1993</td>\n",
       "      <td>14.087719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1994</td>\n",
       "      <td>16.469388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1995</td>\n",
       "      <td>13.622222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1996</td>\n",
       "      <td>13.877193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1997</td>\n",
       "      <td>12.156863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1998</td>\n",
       "      <td>15.184332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1999</td>\n",
       "      <td>22.090433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2000</td>\n",
       "      <td>22.336207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2001</td>\n",
       "      <td>20.295828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2002</td>\n",
       "      <td>18.929193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2003</td>\n",
       "      <td>19.677656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2004</td>\n",
       "      <td>19.171913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2005</td>\n",
       "      <td>16.292149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2006</td>\n",
       "      <td>16.685924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2007</td>\n",
       "      <td>16.893462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2008</td>\n",
       "      <td>17.272917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2009</td>\n",
       "      <td>15.327173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2010</td>\n",
       "      <td>16.800041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2011</td>\n",
       "      <td>23.188479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2012</td>\n",
       "      <td>25.275396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2013</td>\n",
       "      <td>21.408757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2014</td>\n",
       "      <td>22.925073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2015</td>\n",
       "      <td>22.993741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2016</td>\n",
       "      <td>22.940563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2017</td>\n",
       "      <td>23.088092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2018</td>\n",
       "      <td>22.653952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2019</td>\n",
       "      <td>20.695452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2020</td>\n",
       "      <td>22.571142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2021</td>\n",
       "      <td>25.438547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2022</td>\n",
       "      <td>22.105330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2023</td>\n",
       "      <td>24.226228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Year        AQI\n",
       "0   1984  20.000000\n",
       "1   1985  21.385965\n",
       "2   1986  15.786885\n",
       "3   1987  26.490000\n",
       "4   1988  16.546296\n",
       "5   1991  18.545455\n",
       "6   1992  15.396552\n",
       "7   1993  14.087719\n",
       "8   1994  16.469388\n",
       "9   1995  13.622222\n",
       "10  1996  13.877193\n",
       "11  1997  12.156863\n",
       "12  1998  15.184332\n",
       "13  1999  22.090433\n",
       "14  2000  22.336207\n",
       "15  2001  20.295828\n",
       "16  2002  18.929193\n",
       "17  2003  19.677656\n",
       "18  2004  19.171913\n",
       "19  2005  16.292149\n",
       "20  2006  16.685924\n",
       "21  2007  16.893462\n",
       "22  2008  17.272917\n",
       "23  2009  15.327173\n",
       "24  2010  16.800041\n",
       "25  2011  23.188479\n",
       "26  2012  25.275396\n",
       "27  2013  21.408757\n",
       "28  2014  22.925073\n",
       "29  2015  22.993741\n",
       "30  2016  22.940563\n",
       "31  2017  23.088092\n",
       "32  2018  22.653952\n",
       "33  2019  20.695452\n",
       "34  2020  22.571142\n",
       "35  2021  25.438547\n",
       "36  2022  22.105330\n",
       "37  2023  24.226228"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aqi_yearly_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7a0c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the aqi_df dataframe\n",
    "aqi_df.to_csv(\"final_aqi_each_year.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92b9b9d",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "[1] EPA AQI API, https://aqs.epa.gov/aqsweb/documents/data_api.html\n",
    "\n",
    "### * This snippet was taken from the example notebook(s) provided by Dr. David McDonald "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
